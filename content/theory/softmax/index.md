---
title: Softmax
type: docs
description: Softmax
weight: 10
---

### 原始公式

对于一个包含 \( K \) 个类别的分类问题，给定一个输入向量 \( \mathbf{z} = [z_1, z_2, \dots, z_K] \)，Softmax 函数将每个元素 \( z_i \) 映射为一个概率值 \( p_i \)，公式为：

\[
p_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}} \quad \text{for } i = 1, 2, \dots, K
\]

其中：
- \( e^{z_i} \) 是指数函数，将 \( z_i \) 转换为正数；
- 分母是所有 \( e^{z_j} \) 的总和，确保所有输出概率之和为 1，即：
  \[
  \sum_{i=1}^{K} p_i = 1
  \]

Softmax 具备以下 **特点**：

1. 将任意实数向量转换为概率分布（每个值在 0 到 1 之间，总和为 1）。
2. 突出最大值（通过指数放大差异），常用于多分类模型的输出层。

#### 实例

若 \( \mathbf{z} = [2.0, 1.0, 0.1] \)，则：
- 计算指数：\( e^2 \approx 7.39 \), \( e^1 \approx 2.72 \), \( e^{0.1} \approx 1.11 \)
- 分母和：\( 7.39 + 2.72 + 1.11 = 11.22 \)
- 概率：
  \[
  p_1 = \frac{7.39}{11.22} \approx 0.659,\quad
  p_2 = \frac{2.72}{11.22} \approx 0.242,\quad
  p_3 = \frac{1.11}{11.22} \approx 0.099
  \]

### 数值稳定的版本

原始 Softmax 公式在实际计算时可能会遇到数值问题：

- 如果某个输入值 \( x_k \) 非常大（例如 1000），那么 \( e^{1000} \) 会超出计算机浮点数的表示范围，造成“上溢出”。
- 如果所有输入值 \( x_j \) 都是绝对值很大的负数，那么 \( e^{x_j} \) 可能会小到被计算机视为 0，导致分母为 0 的“除零错误”。

在数学上，数字可以无限大或无限小，但计算机使用固定范围的数值类型来存储数字。因此，为了保证计算稳定，我们通常使用以下**数值稳定版本的 Softmax**：

首先，找出所有输入中的最大值 \( M = \max(x) \)，然后将每个输入减去该最大值，再进行 Softmax 计算：

\[
\text{softmax}(x_i) = \frac{e^{x_i - M}}{\sum_{j=1}^{n} e^{x_j - M}}
\]

这样做可以避免数值溢出问题，同时不影响 Softmax 的输出结果。

**那么为什么这样正确呢？**

因为这是一个分子分母同时乘以 \( e^{-M} \) 的等价变换：

\[
\frac{e^{x_i}}{\sum_j e^{x_j}} = \frac{e^{x_i} \cdot e^{-M}}{\sum_j e^{x_j} \cdot e^{-M}} = \frac{e^{x_i - M}}{\sum_j e^{x_j - M}}
\]

- 变换后，最大的指数项 \( e^{M - M} = e^0 = 1 \)，其他项 \( e^{x_j - M} \le 1 \)。
- 这保证了所有指数值都在 \( (0, 1] \) 范围内，避免了上溢出。
- 同时，因为至少有一个值为 1，分母不会为 0，避免了下溢导致的除零错误。

####  示例
设 \( \mathbf{x} = [1000, 1001, 1002] \)：
- **原始计算**：\( e^{1002} \) 会溢出。
- **稳定方法**：
  - \( M = 1002 \)
  - 计算 \( \mathbf{x} - M = [-2, -1, 0] \)
  - 计算指数：\( e^{-2} \approx 0.1353,\ e^{-1} \approx 0.3679,\ e^{0} = 1 \)
  - 分母和：\( 0.1353 + 0.3679 + 1 = 1.5032 \)
  - 概率：\( [0.0900,\ 0.2447,\ 0.6652] \)
